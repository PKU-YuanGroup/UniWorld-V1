# we recommend to read config_details.yaml first.


ckpt_path: '/data/logs/tad/tad_128_s_p1_100kx1024_cls0p25_dec2at4/checkpoints/0100000.pt' # <---- download our pre-trained dit or your own checkpoint

data:
  data_path: '/data/checkpoints/LanguageBind/offline_feature/offline_vae_128/imagenet_train_128' # <---- path to your data. it is generated by extract_features.py.
                                 #       if you just want to inference, download our latent_stats.pt and give its path here is ok.
  fid_reference_file: '/data/checkpoints/VIRTUAL_imagenet128_labeled.npz' # <---- path to your fid_reference_file.npz. download it from ADM

  # recommend to use default settings
  image_size: 128
  num_classes: 1000
  num_workers: 16
  latent_norm: false
  latent_multiplier: 0.18215

# recommend to use default settings (we wil release codes with SD-VAE later)
vae:
  model_path: '/data/checkpoints/stabilityai/sd-vae-ft-ema'
  downsample_ratio: 8

# recommend to use default settings
model:
  model_type: TAD-S/1
  use_qknorm: false
  use_swiglu: false
  use_rope: false
  use_rmsnorm: false
  in_chans: 4
  use_checkpoint: false
  causal_timestep: false
  timestep_descending: false
  timestep_tokenwise: false
  gen_info:
    enable: true
  cls_info:
    enable: true
    num_classes: 1000
    cls_on_token: false
    refresh: false
    num_decoder_block: 2
    encoder_depth: 4

cls_loss:
  smoothing: 0.1
  cls_w: 0.25

# recommend to use default settings
train:
  max_steps: 100000
  global_batch_size: 1024
  global_seed: 0
  output_dir: '../logs/tad/tad_128_s_p1_100kx1024_cls0p25_dec2at4'
  ckpt: null
  log_every: 100
  ckpt_every: 20000
  wandb: true
  seed: 1234
  precision: 'bf16'
optimizer:
  lr: 0.0002
  beta2: 0.999
wandb:
  proj_name: 'tad'
  log_name: 'tad_128_s_p1_100kx1024_cls0p25_dec2at4'
  key: '953e958793b218efb850fa194e85843e2c3bd88b'

scheduler:
  diffusion: true
  transport: false

diffusion: 
  learn_sigma: true
  diffusion_steps: 1000

# recommend to use default settings
transport:
  path_type: Linear
  prediction: velocity
  loss_weight: null
  sample_eps: null
  train_eps: null
  use_cosine_loss: true
  use_lognorm: true

# recommend to use default settings
sample:
  num_sampling_steps: 250
  cfg_scale: 1.0
  # recommend to use default settings
  per_proc_batch_size: 64
  fid_num: 50000
  cfg_interval_start: 0.0