import os
import json
import torch
import gradio as gr
import numpy as np
import random
from transformers import MarianTokenizer, MarianMTModel
import json
import os
from PIL import Image, ImageDraw, ImageColor
from typing import Union, Sequence, Tuple


# å…¨å±€çŠ¶æ€
DATA = []
INDEX = 0
IMG_ROOT = ""
RED_BOX_PREFIX = ""
OUTPUT_DIR = ""
DISPLAY_ORDER = []  # ç”¨äºè®°å½•æ¯ä¸ªæ ·æœ¬çš„å›¾ç‰‡å±•ç¤ºé¡ºåº

model_name = "/mnt/data/checkpoints/Helsinki-NLP/opus-mt-en-zh"
tokenizer = MarianTokenizer.from_pretrained(model_name)
model = MarianMTModel.from_pretrained(model_name)
device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')
model = model.to(device=device, dtype=torch.bfloat16)
model = torch.compile(model)



def draw_boxes(
    img_input: Union[str, Image.Image],
    boxes: Sequence[Tuple[int, int, int, int]],
    width: int = 50,
    color: Union[str, Tuple[int, int, int]] = "red",
    border_opacity: float = 0.6
) -> Image.Image:
    """
    åœ¨å›¾ç‰‡ä¸Šç”»å¤šä¸ªåŠé€æ˜è¾¹æ¡†ï¼ˆæ— å¡«å……ï¼‰ã€‚

    Args:
        img_input: å›¾ç‰‡è·¯å¾„æˆ– PIL.Image å¯¹è±¡ã€‚
        boxes: List of boxesï¼Œæ¯ä¸ª box æ˜¯ (xmin, ymin, xmax, ymax)ã€‚
        width: è¾¹æ¡†çº¿å®½ï¼Œé»˜è®¤ä¸º 50 åƒç´ ã€‚
        color: è¾¹æ¡†é¢œè‰²ï¼Œå¯ä¸ºå­—ç¬¦ä¸²ï¼ˆå¦‚ "red"ï¼‰æˆ– RGB ä¸‰å…ƒç»„ã€‚
        border_opacity: è¾¹æ¡†é€æ˜åº¦ï¼Œ0 å®Œå…¨é€æ˜ï¼Œ1 å®Œå…¨ä¸é€æ˜ï¼Œé»˜è®¤ 0.5ã€‚

    Returns:
        å¸¦æœ‰åŠé€æ˜è¾¹æ¡†çš„ PIL.Image å¯¹è±¡ï¼ˆRGBA æ¨¡å¼ï¼‰ã€‚
    """
    # 1. æ‰“å¼€å¹¶è½¬æ¢ä¸º RGBA
    if isinstance(img_input, str):
        base = Image.open(img_input).convert("RGBA")
    else:
        base = img_input.convert("RGBA")

    # 2. æ–°å»ºé€æ˜å åŠ å±‚
    overlay = Image.new("RGBA", base.size, (0,0,0,0))
    draw = ImageDraw.Draw(overlay)

    # 3. è§£æ color å¹¶è®¡ç®—å¸¦é€æ˜åº¦çš„ RGBA
    if isinstance(color, str):
        rgb = ImageColor.getrgb(color)
    else:
        rgb = color
    alpha = int(255 * border_opacity)
    rgba = (rgb[0], rgb[1], rgb[2], alpha)

    # 4. åœ¨ overlay ä¸Šç”»åªæœ‰ outline çš„åŠé€æ˜æ¡†
    for xmin, ymin, xmax, ymax in boxes:
        draw.rectangle(
            [(xmin, ymin), (xmax, ymax)],
            outline=rgba,
            width=width
        )

    # 5. åˆæˆå¹¶è¿”å›
    return Image.alpha_composite(base, overlay)


def translate_hf(texts):
    batch = tokenizer(texts, return_tensors="pt", padding=True).to(device)
    translated = model.generate(**batch)
    return tokenizer.decode(translated[0], skip_special_tokens=True)

# è·å–å¹¶å±•ç¤ºæ ·æœ¬
def get_sample(idx):
    sample = DATA[idx]
    # åŸå§‹è·¯å¾„
    basename = sample['image']
    src_path = os.path.join(IMG_ROOT, basename)
    boxes = [[box['xmin'], box['ymin'], box['xmax'], box['ymax']] for box in sample['boxes']]
    # image = draw_boxes(src_path, boxes, width=10, color="red")
    image = src_path
    path_with = os.path.join(IMG_ROOT, f'{RED_BOX_PREFIX}{basename}')
    path_without = os.path.join(IMG_ROOT, f'kontext_out_{basename}')
    # æ ¹æ® DISPLAY_ORDER å†³å®šé¡ºåº
    swap = DISPLAY_ORDER[idx]
    if swap:
        gallery_images = [path_without, path_with]
        order_info = ['without_redbox', 'with_redbox']
    else:
        gallery_images = [path_with, path_without]
        order_info = ['with_redbox', 'without_redbox']

    # ä¿å­˜ä¸Šä¸€è½® order ä¿¡æ¯ï¼Œç”¨äºæäº¤æ—¶å†™å…¥æ–‡ä»¶
    sample['_last_order'] = order_info

    en = sample['prompt']
    cn = translate_hf(en)
    text = f"{cn} ({en})"

    status = f"å½“å‰æ ·æœ¬: {idx + 1} / {len(DATA)}\n"
    ann_path = os.path.join(OUTPUT_DIR, f"annotation_{idx}.json")
    status += "æ ‡è®°çŠ¶æ€: å·²æ ‡è®° âœ…" if os.path.exists(ann_path) else "æ ‡è®°çŠ¶æ€: æœªæ ‡è®° âŒ"
    print(gallery_images)
    return (
        [image],
        gallery_images,
        gr.update(value=text),
        gr.update(value=status),
        gr.update(value=None),
        gr.update(value=None),
        gr.update(value=None)
    )

# å¯¼èˆªå‡½æ•°
def show_first():
    global INDEX
    INDEX = 0
    return get_sample(INDEX)

def show_next():
    global INDEX
    if INDEX < len(DATA) - 1:
        INDEX += 1
    return get_sample(INDEX)

def show_prev():
    global INDEX
    if INDEX > 0:
        INDEX -= 1
    return get_sample(INDEX)

def jump_to_index(target_idx):
    global INDEX
    try:
        target_idx = int(target_idx)
        if 0 <= target_idx < len(DATA):
            INDEX = target_idx
            return get_sample(INDEX)
        else:
            return (
                gr.update(),
                gr.update(),
                gr.update(value=f"âŒ ç´¢å¼•è¶…å‡ºèŒƒå›´ (0 - {len(DATA)-1})"),
                gr.update(value=f"âŒ æ— æ•ˆç´¢å¼•: {target_idx}"),
                gr.update(),
                gr.update(),
                gr.update()
            )
    except ValueError:
        return (
            gr.update(),
            gr.update(),
            gr.update(value="âŒ ç´¢å¼•å¿…é¡»æ˜¯æ•´æ•°"),
            gr.update(value="âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—ç´¢å¼•"),
            gr.update(),
            gr.update(),
            gr.update()
        )

def show_first_unmarked():
    global INDEX
    for idx in range(len(DATA)):
        ann_path = os.path.join(OUTPUT_DIR, f"annotation_{idx}.json")
        if not os.path.exists(ann_path):
            INDEX = idx
            return get_sample(INDEX)
    return (
        gr.update(),
        gr.update(),
        gr.update(value="âœ… å…¨éƒ¨å·²ç»å®Œæˆ"),
        gr.update(value="âœ… æ— æœªæ ‡è®°æ ·æœ¬"),
        gr.update(),
        gr.update(),
        gr.update()
    )

# æ ‡æ³¨å¹¶ä¿å­˜ç»“æœå¹¶è·³è½¬åˆ°ç¬¬ä¸€ä¸ªæœªæ ‡è®°æ ·æœ¬
def submit_annotation(region_completion, target_accuracy, stability):
    global INDEX, DATA, OUTPUT_DIR
    if region_completion is None or target_accuracy is None or stability is None:
        return (
            "âŒ è¯·å®Œæˆæ‰€æœ‰æ ‡æ³¨åå†æäº¤",
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update()
        )

    sample = DATA[INDEX]
    order_info = sample['_last_order']
    result = {
        "index": INDEX,
        "first_image": order_info[0],
        "second_image": order_info[1],
        "ç¼–è¾‘åŒºåŸŸæŒ‡ä»¤å®Œæˆåº¦": region_completion,
        "ç›®æ ‡åŒºåŸŸå˜åŒ–å‡†ç¡®åº¦": target_accuracy,
        "éç¼–è¾‘åŒºåŸŸç¨³å®šæ€§": stability
    }
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    out_path = os.path.join(OUTPUT_DIR, f"annotation_{INDEX}.json")
    with open(out_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    msg = f"ä¿å­˜æˆåŠŸ: {out_path}"
    # è·³è½¬åˆ°ç¬¬ä¸€ä¸ªæœªæ ‡è®°
    for idx in range(len(DATA)):
        if not os.path.exists(os.path.join(OUTPUT_DIR, f"annotation_{idx}.json")):
            INDEX = idx
            return (msg,) + get_sample(INDEX)
    return (msg,) + (
        gr.update(),
        gr.update(),
        gr.update(value="âœ… å…¨éƒ¨å·²ç»å®Œæˆ"),
        gr.update(value="âœ… æ— æœªæ ‡è®°æ ·æœ¬"),
        gr.update(),
        gr.update(),
        gr.update()
    )

# åŠ è½½ JSON æ•°æ®
def load_json(json_path, image_root, red_box_prefix, output_dir):
    global DATA, INDEX, IMG_ROOT, RED_BOX_PREFIX, OUTPUT_DIR, DISPLAY_ORDER
    try:
        with open(json_path.strip(), 'r', encoding='utf-8') as f:
            DATA = json.load(f)
    except Exception as e:
        return f"âŒ Failed to load JSON: {e}", None, None, "", "", None, None, None
    IMG_ROOT = image_root.strip()
    RED_BOX_PREFIX = red_box_prefix.strip()
    OUTPUT_DIR = output_dir.strip()
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    # ä¸ºæ¯ä¸ªæ ·æœ¬éšæœºå†³å®šå±•ç¤ºé¡ºåº
    DISPLAY_ORDER = [random.choice([False, True]) for _ in range(len(DATA))]
    # DISPLAY_ORDER = [False for _ in range(len(DATA))]
    INDEX = 0
    return (f"âœ… Loaded {len(DATA)} samples.",) + get_sample(INDEX)

# Gradio ç•Œé¢
with gr.Blocks() as demo:
    gr.Markdown("##  Data Online comparison (æ•°æ®åœ¨çº¿ç­›é€‰å™¨)")
    gr.Markdown(
        """
        **æŒ‡ä»¤å®Œæˆåº¦**ï¼šåªéœ€è¦å…³æ³¨æŒ‡ä»¤å®Œæˆåº¦ï¼Œæ¯”å¦‚æŒ‡ä»¤ï¼šè®©ä¸€ä¸ªäººä¸¾èµ·å·¦æ‰‹ã€‚ç¬¬ä¸€å¼ å›¾ä¸¾èµ·å·¦æ‰‹åŒæ—¶å³æ‰‹ä¹Ÿä¸¾èµ·äº†ï¼Œç¬¬äºŒå¼ å›¾ä¸¾èµ·å³æ‰‹ã€‚ä»ç„¶åˆ¤æ–­å¹³å±€
        
        **ç›®æ ‡åŒºåŸŸå˜åŒ–å‡†ç¡®åº¦**ï¼šæ˜¯ä¸æ˜¯åªåœ¨æ”¹å˜çš„åœ°æ–¹å˜ï¼Œä¸æ”¹å˜çš„åœ°æ–¹ä¸å˜ã€‚æ¯”å¦‚è®©å³è¾¹åŠ ä¸ªäººï¼Œç¬¬ä¸€å¼ å›¾åŠ æˆäº†ç‹—ï¼Œç¬¬äºŒå¼ å›¾åŠ äº†äººï¼Œä½†ä¾ç„¶å¹³å±€
        
        **å‚è€ƒå›¾ä¸€è‡´æ€§**ï¼šå’Œå‚è€ƒå›¾çš„ä¸€è‡´æ€§ã€‚æ¯”å¦‚éƒ½ç¼–è¾‘æˆåŠŸäº†ï¼Œä½†æ˜¯ç¬¬ä¸€ä¸ªå›¾æ¯”ç¬¬äºŒä¸ªå›¾æ›´åƒå‚è€ƒå›¾çš„äººï¼Œé‚£å°±ç¬¬ä¸€å¼ å›¾èµ¢ã€‚ä½†å¦‚æœç¬¬ä¸€å¼ å›¾å°‘äº†è½¦ï¼Œç¬¬äºŒå¼ å›¾å¤šäº†è½¦ï¼Œè¿™åº”å½“åœ¨ç›®æ ‡åŒºåŸŸå˜åŒ–å‡†ç¡®åº¦è¿›è¡Œåˆ¤æ–­è€Œä¸æ˜¯ç¼–è¾‘ä¸€è‡´æ€§
        """
    )
    gr.Markdown(
        """
        **ç‰¹åˆ«å¤‡æ³¨**ï¼šå¦‚æœä¸€ä¸ªå›¾ç‰‡ä¸­å‡ºç°äº†çº¢æ¡†ï¼Œé‚£ä¹ˆè¯·å¿½ç•¥è¿™ä¸ªçº¢æ¡†ï¼Œå› ä¸ºåŸºæ¨¡å‹æœªç»å¾®è°ƒ
        """
    )
    with gr.Row():
        json_path    = gr.Textbox(label="JSON file path (JSONæ–‡ä»¶è·¯å¾„)")
        image_root   = gr.Textbox(label="Image root directory (å›¾ç‰‡æ ¹ç›®å½•)")
        red_box_prefix   = gr.Textbox(label="Red Box Image Prefix (Red Boxå›¾ç‰‡å‰ç¼€)")
        approved_dir = gr.Textbox(label="Output dir (è¾“å‡ºç›®å½•)")
        load_btn     = gr.Button("Load JSON (åŠ è½½ JSON)")
        load_status  = gr.Textbox(label="Loading status (åŠ è½½çŠ¶æ€)", interactive=False)

    with gr.Row():
        with gr.Column(scale=0.7):
            src_gallery  = gr.Gallery(label="Source Image (æºå›¾)", columns=1, allow_preview=True, show_label=True, height="auto", object_fit="contain")
            text_box     = gr.Textbox(label="Conversation Content (å¯¹è¯å†…å®¹)", lines=2, interactive=False)
        with gr.Column():
            gallery      = gr.Gallery(label="Image Preview (å›¾ç‰‡é¢„è§ˆ/ç‚¹å‡»å¯æ”¾å¤§å¯¹æ¯”)", columns=2, allow_preview=True, show_label=True, height="auto", object_fit="contain")
            sample_status = gr.Textbox(label="æ ·æœ¬çŠ¶æ€", interactive=False)

    with gr.Row():
        prev_btn     = gr.Button("âŸµ Previous (å‘å‰)")
        next_btn     = gr.Button("Next âŸ¶ (å‘å)")
        jump_index   = gr.Number(label="ç´¢å¼•è·³è½¬", precision=0)
        jump_btn     = gr.Button("ğŸ” Jump (è·³è½¬)")
        first_unmarked_btn = gr.Button("â© First Unmarked (è·³åˆ°æœªæ ‡è®°æ ·æœ¬)")

    with gr.Row():
        region_completion = gr.Radio(["ç¬¬ä¸€å¼ ", "ç¬¬äºŒå¼ ", "å¹³å±€"], label="æŒ‡ä»¤å®Œæˆåº¦", type="value")
        target_accuracy   = gr.Radio(["ç¬¬ä¸€å¼ ", "ç¬¬äºŒå¼ ", "å¹³å±€"], label="ç›®æ ‡åŒºåŸŸå˜åŒ–å‡†ç¡®åº¦", type="value")
        stability         = gr.Radio(["ç¬¬ä¸€å¼ ", "ç¬¬äºŒå¼ ", "å¹³å±€"], label="å‚è€ƒå›¾ä¸€è‡´æ€§", type="value")
    submit_btn        = gr.Button("æäº¤æ ‡æ³¨è‡ªåŠ¨ä¸‹ä¸€ä¸ª")
    submit_status     = gr.Textbox(label="æäº¤çŠ¶æ€", interactive=False)

    load_btn.click(
        load_json,
        inputs=[json_path, image_root, red_box_prefix, approved_dir],
        outputs=[load_status, src_gallery, gallery, text_box, sample_status, region_completion, target_accuracy, stability]
    )

    prev_btn.click(show_prev, outputs=[src_gallery, gallery, text_box, sample_status, region_completion, target_accuracy, stability])
    next_btn.click(show_next, outputs=[src_gallery, gallery, text_box, sample_status, region_completion, target_accuracy, stability])
    jump_btn.click(jump_to_index, inputs=[jump_index], outputs=[src_gallery, gallery, text_box, sample_status, region_completion, target_accuracy, stability])
    first_unmarked_btn.click(show_first_unmarked, outputs=[src_gallery, gallery, text_box, sample_status, region_completion, target_accuracy, stability])

    submit_btn.click(
        submit_annotation,
        inputs=[region_completion, target_accuracy, stability],
        outputs=[submit_status, src_gallery, gallery, text_box, sample_status, region_completion, target_accuracy, stability]
    )

if __name__ == "__main__":
    server_port = os.getenv('PORT', None)
    server_name = None
    if server_port is not None:
        server_port = int(server_port)
        server_name = '0.0.0.0'
    demo.launch(allowed_paths=['/'], server_port=server_port, server_name=server_name)



'''
/mnt/data/datasets/imgedit/Benchmark/imgedit_bench_anno_box.json
/mnt/data/datasets/imgedit/Benchmark/imgedit_bench_images
kontext_out_red_box_w10_
/mnt/data/lb/6.5/UniWorld-V1/comfyui/compare_imgedit_bench_w10
PORT=10000 python univa/serve/compare_data_bench.py

/mnt/data/datasets/black-forest-labs/kontext-bench/kontext_bench_anno_box.json
/mnt/data/datasets/black-forest-labs/kontext_bench_images
kontext_out_red_box_w30_
/mnt/data/lb/6.5/UniWorld-V1/comfyui/compare_kontext_bench_w30
PORT=10001 python univa/serve/compare_data_bench.py

/mnt/data/datasets/stepfun-ai/gedit_bench_anno_box.json
/mnt/data/datasets/stepfun-ai/gedit_bench_images
kontext_out_red_box_w10_
/mnt/data/lb/6.5/UniWorld-V1/comfyui/compare_gedit_bench_w10
PORT=10002 python univa/serve/compare_data_bench.py
'''